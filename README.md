# Generative-AI-Langchain-Huggingface


Python Programming (NumPy, Pandas, OOP, File Handling, etc.)

NLP & Deep Learning:

RNN, LSTM, GRU, Bidirectional RNNs

Encoder-Decoder architectures

Attention Mechanisms, Transformer & BERT
-------------------------------------------------------
>> LangChain Ecosystem:

LangChain Core, LangChain Community, LangChain Tools

Building chains, retrieval-based systems, chatbot memory, and more

Generative AI Project Development:

RAG (Retrieval-Augmented Generation) systems

Chatbots

Text summarization tools

Search engines

Multi-agent AI applications

ðŸ”§ Technologies & Tools Used
Frameworks: LangChain, Streamlit, CrewAI
---------------------------------------------------------
>> LLMs:

Paid: OpenAI (GPT-4, GPT-4 Turbo), OpenAI Embeddings

Open Source: Google Gemma 2, Meta LLaMA 3, Code LLaMA, Mistral (Anthropic)

HuggingFace models
--------------------------------------------------------
>> Infrastructure & Deployment:

Google Colab for training & fine-tuning

AWS (Bedrock, Lambda, API Gateway, SageMaker)

Nvidia NIM for scalable cloud-based GenAI apps

Grok (LPU-based inference engine)


--------------------------------------------------------
>> Fine-tuning LLMs with:

Quantization techniques

LoRA/QLoRA

Working with multi-modal LLMs

Building real-world, production-grade projects

Using free resources to deploy and test applications

---------------------------------------------------------------------------

Build and deploy your own Generative AI products

Understand and leverage cutting-edge GenAI frameworks and libraries

Work with both cloud and open-source LLM infrastructure

Be interview-ready and startup-ready in the field of Generative A
